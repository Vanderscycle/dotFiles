#+title: Terraform
#+author:    Henri Vandersleyen
#+email:     henri-vandersleyen@protonmail.com

* Terraform Basic
** Table of Content
Terraform is used as an extensible and powerful tool

** Basic structure
*** File

The basic file structure of a `.tf` file is as follow.
#+begin_src terraform
<block> <resource type> <resource name> {
# arguments
    key1 = value1
    key2 = value2
}
#+end_src
Nomenclature

*** Folder

A simple project terraform folder structure:
#+begin_src terraform
.
└── tf/
    ├── versions.tf
    ├── variables.tf
    ├── provider.tf
    ├── droplets.tf
    ├── dns.tf
    ├── data-sources.tf
    └── external/
        └── name-generator.py
#+end_src


a more complex terraform folder structure:
#+begin_src terraform
.
└── tf/
├── modules/
│   ├── network/
│   │   ├── main.tf
│   │   ├── dns.tf
│   │   ├── outputs.tf
│   │   └── variables.tf
│   └── spaces/
│       ├── main.tf
│       ├── outputs.tf
│       └── variables.tf
└── applications/
├── backend-app/
│   ├── env/
│   │   ├── dev.tfvars
│   │   ├── staging.tfvars
│   │   ├── qa.tfvars
│   │   └── production.tfvars
│   └── main.tf
└── frontend-app/
├── env/
│   ├── dev.tfvars
│   ├── staging.tfvars
│   ├── qa.tfvars
│   └── production.tfvars
└── main.tf
#+end_src

**** File explanation
- main.tf - call modules, locals, and data sources to create all resources
- variables.tf - contains declarations of variables used in main.tf
- outputs.tf - contains outputs from the resources created in main.tf
- versions.tf - contains version requirements for Terraform and providers
- resources.tf - ??
- providers.tf - version control for provides

** Basic Workflow
1. Create resources
2. `terraform init`
3. `terraform plan -out=output.tfplan`
4. `terraform apply output.tfplan`
   - idempotent config meaning that futher plan/apply will mirror
5. `terraform destroy` will destroy all ressources in the folder

When using terraform plan and apply, we want the have the exact configuration listed in the `main.tf`. This entails destroying ressources (e.g a change in file name)  to create new ones.

You should always `plan` before `applying` even if you are not required.
#+begin_src bash
terraform init
terraform plan -out=output.tfplan
#terraform apply output.tfplan
#+end_src

#+RESULTS:
** Debugging
1. `Terrafrom show` to show the resource state.
2. `Terraform output` to show defined `output.tf` values

** Terraform providers
When executing `terraform init` it will pull all of the listed terraform provides. There are several types of provides:
- Official (Terraform)
- Partner (e.g. heroku, digitalOcean)
- OSS (community)
`terraform init` is a safe command that can be run any number of times init.
Should the provider's version be specified (which you should) then populate the `provides.tf`

Each different providers will be downloaded upon `terraform init` inside `.terraform/plugins/`


** Input variables

Contend of a `variables.tf`
#+begin_src terraform
variable "byte_length" {
  default = 8
}
#+end_src

Contend of a `main.tf` in the same folder as `variables.tf`
#+begin_src terraform
resource "random_id" "server" {
  byte_length = var.byte_length
}
#+end_src

Current folder will look like this
#+begin_src
❯ ls
drwxr-xr-x    - henri 10 Mar 07:55 .terraform
.rw-r--r--  290 henri 11 Mar 22:05 main.tf
.rw-r--r-- 2.3k henri 10 Mar 07:57 output.tfplan
.rw-r--r-- 2.0k henri 11 Mar 21:19 terraform.tfstate
.rw-r--r--  141 henri 11 Mar 22:05 variables.tf
drwxr-xr-x    - henri 10 Mar 07:57 ~
#+end_src

**  Variable block

Recommended setup for variable definition

#+begin_src terraform
variable "file_permisson" {
  default = "0700"
  type = string
  description = "permissions associated with the file"
}
#+end_src

The only variable types are:

| Type   | Example        |
|--------+----------------|
| string | "hello mom"    |
| number | 1              |
| bool   | true/false     |
| any    | Default Value  |
| list   | ["cat", "dog"] |
| map    | pet1=cat       |
| object |                |
| tuple  |                |

Complex data type:
**** List
#+begin_src terraform
variable "file_permisson" {
  default = [ "0700" "777"]
  type = list(string)
  description = "list of allowed permissions"
}

resource "local_file" "foo" {
  filename = "${path.module}/foo.txt"
  content = var.content
  file_permission = var.file_permission[0]
}
#+end_src

the `list` type support greater accuracy with list(string/number)

**** Map
#+begin_src terraform
variable "file_permisson" {
  default = {
    "secret" = "700"
    "admin"  "777"
    }
  type = map(string)
  description = "Map of allowed permissions"
}

resource "local_file" "foo" {
  filename = "${path.module}/foo.txt"
  content = var.content
  file_permission = var.file_permission["admin"]
}
#+end_src


the `map` type support greater accuracy with map(string/number)

**** 
A set is a list that cannot have a duplicate element. Same with subtyples `set(string/number)`

**** Object
#+begin_src terraform
variable "bob" {
  default = {
    name = "bob"
    color = "no importance"
    age = 33
    food = ["humous" , "feta"]
    permission = "777"

    }
  type = object({
  name = string
  color = string
  age = number
  food = list(string)
  permission = string})
  description = "Object of employee type privileges and info"
}

resource "local_file" "foo" {
  filename = "${path.module}/foo.txt"
  content = var.content
  file_permission = var.bob["permission"]
}
#+end_src

**** Tuples
#+begin_src terraform
variable "bob" {
  default = [ 43, "777" , true]
  type = tuple([number, string, bool])
  description = "Object of employee type privileges and info"
}

resource "local_file" "foo" {
  filename = "${path.module}/foo.txt"
  content = var.content
  file_permission = var.bob[1]
}
#+end_src

**** Variable definition
Similar to lists but can be of different variable types.
`default`, `type` and `description` greatly enhance the code longevity. If no default is supplied, `terraform apply` will ask you for the variable's value. Otherwise you can supply them in the cli or pass them as an export var `export TF_VAR_FILENAME="/root/pets.txt"`
#+begin_src bash
terrafrom apply -var "filename=/root/pets.txt" -var "content=We love Pets" ...
 #+end_src

An alternative is to store them inside a `terraform.tfvars` or `terraform.tfvars.json`, `*.auto.tfvars`, `*.auto.tfvars.json` which will be automatically loaded. Any other name will require an extra flag for the cli `-var-file variables.tfvars`
#+begin_src tfvars
filename = "/root/pets.txt"
content = "We love pets!"
#+end_src

Order for precedence: (lowest to highest)
1. Env vars `TF_VAR`
2. Terraform.tfvars
3. *.auto.tfvars (and other)
4. cli

** Resource Attributes

How to feed the output of one ressource into another (e.g. create dependencies)
#+begin_src terraform
resource "local_file" "pet" {
  filename = "${path.module}/pet.txt"
  content = "My favorite foo is ${random_pet.my-per.id}" # the `$` is an main
}
resource "random_pet" "my-pet" {}
#+end_src
The required pattern is `resource_type.resource_name.attribute`. If unusre what attribute, then run `terraform plan`
To inspect the attributes values use `terraform show`

** Resource dependencies
Terraform is smart enough to figure out the `implicit dependencies` see above example. However is can be `explicit` uesfull when a resource is inderectly dependent on another one.
#+begin_src terraform
resource "local_file" "pet" {
  filename = "${path.module}/pet.txt"
  content = "My favorite foo is big bob"

  depends_on = [
    random_pet.my-pet
  ]
}
resource "random_pet" "my-pet" {}
#+end_src

** Output variables
To define desired output to get something more than just the resource's `id`. `output.tf` is usefull to feed data into let's say ansible.
#+begin_src options
output "<variable_name>" {
value = "<variable_value>"
<arguments>
}
#+end_src

To show the output's value run `terraform output` or `terraform output <variable_name`

* Terraform State

Upon running `terrafrom apply` terraform will create `terraform.tfstate` which managed the infrastructure state. EXTREMELY IMPORTANT for cloud ressources.
You can save the `terraform.tfstate` in an s3 bucket so that the latest version is accessible to the team.
We also cannot disable the state of terrafrom.
Be warned that the statefile may contains plaintext sensitive configuration. Best practice is to store it in remote state backends (e.g. s3 bucket, Terraform Cloud)
Never manually change the tfstate file

* Working with Terrraform

** Other usefull commands
- `terraform validate` instead of using `plan/apply` to check the state. Essentially lint.
    Only validates resources block and the argument syntax, but not the input values
- `terraform show -json` shows the tfstate
- `terraform providers` show all used plugins for resources
- `terraform fmt` formats the tf files
- `terraform output` output all of `outputs.tf` vars
- `terrafrom refresh` automatically ran by `plan/apply`
- `terrafrom graph` shows the terraform dependencies in a graph format. Requires `graphviz` or similar

** Mutable vs immutable infrastructure + lifecycle rules
Mutable IoC: able to change the version of the infrastructure
Immutable: destroy, then creates a new resource (default)

You can modify terraform behavior using the `lifecycle` key/value
#+begin_src terraform
variable "file_permisson" {
  default = "0700"
  type = string
  description = "permissions associated with the file"

}
resource "local_file" "foo" {
  filename = "${path.module}/foo.txt"
  content = "bar"
  file_permission = var.file_permission

  lifecycle {
    create_before_destroy = true
    prevent_destroy = true # e.g. don't drop db
    ignore_changes = [
      content, filename # has to declaratively list what must be changed
    ]
  }
}
#+end_src

For example you may want to prevent certain fields from being changed

** Data sources
Because we can use other tools such as ansible, puppet, saltstack, or do it manually we need a way to read resources that are outside of terraform control. We solve this using datasources.
The datasource block is similar to a resource block.
#+begin_src terraform
data "local_file" "dog" {
  filename = "/root/dog.txt"
}
# To reference the data we use `data.resource_type.ressource_name.attribute`
resource "local_file" "foo" {
  filename = "${path.module}/foo.txt"
  content = data.local_file.dog.content
  file_permission = var.file_permission
}
#+end_src

When reading the documentation you can see its usage between `Resources` and `Data Sources`

** Meta-arguments
- `depends_on`
- `lifecycle`
- `count`
- `for_each`

[[https://developer.hashicorp.com/terraform/language/functions][terraform builtin]] functions documentation
*** Count
#+begin_src terraform

resource "local_file" "pets" {
  filename = var.filename[count.index]
  count = length(var.filename) #buildin functions
}
variable "filename" {
  type = list(string)
  default = [
  "/root/pets.txt",
  "/root/cats.txt",
  "/root/dogo.txt"
  ]
  description = "list of required files"
}
#+end_src

*** For each
Only works with `maps` or a `set` or a list to set convertion using the builting function `toset(var.name)`
#+begin_src terraform

resource "local_file" "pets" {
  filename = var.filename[count.index]
  for_each = toset(var.filename)
}

variable "filename" {
  type = list(string)
  default = [
  "/root/pets.txt",
  "/root/cats.txt",
  "/root/dogo.txt"
  ]
  description = "list of required files"
}
output "pets" {
    values = local_file.pets
}
#+end_src

** version constraints
So that you may track version dependencies

#+begin_src terraform
terraform {
  required_providers {
    local = {
      source = "hashicorp/local"
      version = "2.3.0"
    }
  }
}
resource "local_file" "pets" {
  filename = var.filename[count.index]
  for_each = toset(var.filename)
}
#+end_src

Do not use this version `"!=2.0.0"`
Use version up to`"< 2.0.0"`
Use version at least`"> 2.0.0"`
Only use this version or its `semver` increment `"~> 1.2"` so 1.2 to 1.9
    Can also use greater accuracy `~> 1.2.0` so 1.2.0 to 1.2.9
you can also use them in combinations `"> 1.2.0, < 2.0.0, != 1.4.0"`

** Conditions
if using Terraform >=0.13.0 conditionals are available. `resource`, `variable`, `data source` all can take conditionals.

*** variables

`variables` can take the optional validation tag
#+begin_src yaml
variable "image_id" {
  type        = string
  description = "The id of the machine image (AMI) to use for the server."

  validation {
    condition     = length(var.image_id) > 4 && substr(var.image_id, 0, 4) == "ami-"
    error_message = "The image_id value must be a valid AMI id, starting with \"ami-\"."
  }
}
#+end_src yaml

*** resources, data sources, outputs
`resources`, `data sources`, and `outputs` can take `preconditions` (before evaluation) or `postconditions` (after evaluating the object).
- Use `preconditions` for assumptions
- Use `postconditions` for guarantees

#+begin_src yaml
data "aws_ami" "example" {
  owners = ["amazon"]

  filter {
    name   = "image-id"
    values = ["ami-abc123"]
  }
}

resource "aws_instance" "example" {
  instance_type = "t3.micro"
  ami           = data.aws_ami.example.id

  lifecycle {
    # The AMI ID must refer to an AMI that contains an operating system
    # for the `x86_64` architecture.
    precondition {
      condition     = data.aws_ami.example.architecture == "x86_64"
      error_message = "The selected AMI must be for the x86_64 architecture."
    }

    # The EC2 instance must be allocated a public DNS hostname.
    postcondition {
      condition     = self.public_dns != ""
      error_message = "EC2 instance must be in a VPC that has public DNS hostnames enabled."
    }
  }
}

data "aws_ebs_volume" "example" {
  # Use data resources that refer to other resources to
  # load extra data that isn't directly exported by a resource.
  #
  # Read the details about the root storage volume for the EC2 instance
  # declared by aws_instance.example, using the exported ID.

  filter {
    name = "volume-id"
    values = [aws_instance.example.root_block_device.volume_id]
  }

  # Whenever a data resource is verifying the result of a managed resource
  # declared in the same configuration, you MUST write the checks as
  # postconditions of the data resource. This ensures Terraform will wait
  # to read the data resource until after any changes to the managed resource
  # have completed.
  lifecycle {
    # The EC2 instance will have an encrypted root volume.
    postcondition {
      condition     = self.encrypted
      error_message = "The server's root volume is not encrypted."
    }
  }
}

output "api_base_url" {
  value = "https://${aws_instance.example.private_dns}:8433/"
}
#+end_src yaml

** tags

* Terraform import, tainting, debugging

** taint
Over time, resources that are deployed using Terraform undergo certain configuration changes. The causes may lie in the application layer and the processing logic of various automation tools and processes. This introduces the probability of resources being modified in an undesired manner. For example someone manually changed the infrastructure and instead of using Terraform.

Terraform will mark a ressource as tainted when it fails to run `terraform apply`. Terraform will recreate/replace the resource next time `terraform apply` is run.

To manually taint/untaint a resource
#+begin_src bash
ressource_name = <resource_type>.<resource_name>
terraform taint <resource_name>
terraform untaint <resource_name>
#+end_src

** debugging
For proper debugging it is recommended to change the log level using `export TF_LOG=`
- INFO
- WARNING
- ERROR
- DEBUG
- TRACE
To disable loggin unset the var: `UNSET tf_log_path`

Use var `export TF_LOG_PATH=/tmp/terraform.log` to store the output

** Import
Terraform can import resources created by other methods (e.g. ansible, manually, etx.). This is different from `data source` as terraform cannot update or delete the `data source` resource.
#+begin_src bash
#terraform import <resource_type>.<resource_name> <attribute>
terraform import aws_instace.webserver-2 i-023424
#+end_src
*** workflow

1. declare the resource manually in an empty block.
#+begin_src yaml
resource "aws_instance" "webserver-2"{
# terraform will update
}
#+end_src

2. Then run the `terraform import` command to update terraform state.
3. You can then populate the empty block with required/optional parameters
4. Run `terraform plan`

* Terraform Modules
tldr: modules makes your code reusable and allow for the same abstration as a function.

* Terraform cloud

** Introduction
Store, and manage your terraform state using Terraform cloud.

** CLI login
You will be prompted to add an api token.
#+begin_src bash options
terraform login
#+end_src bash

** variable sets
Variable sets allow you to avoid redefining the same variables across workspaces, so you can standardize common configurations throughout your organization. One common use case for variable sets is for provider credentials.

However, they can be used in similar fashion to your `terraform.tfvars` and have an order of [[https://developer.hashicorp.com/terraform/cloud-docs/workspaces/variables#precedence][precedence]]

** workspaces
Terraform cloud workspaces allow us to groups pieces of infrastructure like `AWS`, `gitlab`, `azure`, etc. However, you need to tell terraform explicitely.
#+begin_src yaml options
terraform {

  cloud {
    organization = "organization-name" # change me

    workspaces {
      name = "learn-terraform-cloud" # change me
    }
  }

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 3.28.0"
    }
  }

  required_version = ">= 1.0.1" # terraform version specific
}

#+end_src yaml

Unless you have a global `variable set` you will need to add it to the workspace.
** Policy enforcement

** Registry
Terraform cloud registry are a reuse existing module through an url, instead of a local file.

* TODO scratch learning AWS [0/1]
- [ ] LEARN ABOUT LOGIC IF etc foten peoples use count for either 0/1
[[https://stackoverflow.com/questions/69918762/how-to-use-a-condition-count-statement-in-terraform][count conditionals]]

[[https://about.gitlab.com/handbook/][handbook]]
- RTFM: gitlab manual
  aim for sudo mono repo -> e.g. Caseri App/corpus app

review terraform modules, but thewy are basicalluy
AWS offers, excellent repos examples. cehck ` terraform-aws-modules`
terraform has logic available most people use ccount for logic, ekse w just use foreach
what are terraform tags again?

critical awz repo `terraform-aws-module` (first place to look) `aws-ia` (egood reference)
https://about.gitlab.com/topics/gitops/gitlab-enables-infrastructure-as-code/
how do I tally aws costs?

The data account will yield the most granular information about the s3 usage.
    The majority of s3 costs are data transfer costs `eu-request-tier1/tier2`
For the total cost of our aws usage, check the root account
